{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用电量预测\n",
    "根据某客户2006年电量数据（见附件），⽤机器学习模型来预测未来⼀小时的电量和未来6小时的⽤电量。数据文件中“time”列是时间戳（⽇期及相应的⼩时、分钟），“KWH”是每个时间戳对应的那个小时⾥的用电量。具体来讲，在每⼀个⼩小时t, 我们需要预测（t+1）⼩时的⽤电量q(t+1)。\n",
    "使用**Mean Absolute Percentage Error**来展示所建模型的预测效果。\n",
    "\n",
    "- 使用XGBoost模型来建⽴立预测模型。\n",
    "- 使用Long Short Term Memory模型来建⽴立预测模型。\n",
    "- 解决预测⼀个6个元素的向量[q(t+1), q(t+2), q(t+3), q(t+4), q(t+5), q(t+6)]的问题。\n",
    "\n",
    "\n",
    "*对于XGBOOST选择了1，3小时前，1，3，7天前的电量，月，日，时作为特征，最后训练集MAPE为0.3%，测试集MAPE为3.1&\n",
    "对于LSTM选择了1，3，7天前的电量，月，日，时等几个特征，时间滑窗为6个小时，预测未来6个小时的耗电量，最后训练集MAPE为8.5%，测试集MAPE为8.3%\n",
    "虽然结果显示XGBOOST效果更好，但是对于这类时间序列问题，可以预见在超参数及特征选择优化后，LSTM的效果会达到XGBOOST同样的水平，甚至超过.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import date, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',parse_dates = ['time'],index_col = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0',axis = 1)\n",
    "data_prep = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hour_shift(data_prep,df,n):\n",
    "    if n> 0:\n",
    "        data_prep[f'{n}_hour_before'] = df['KWH'].shift(n)\n",
    "    else:\n",
    "        data_prep[f'{-n}_hour_after'] = df['KWH'].shift(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_shift(data_prep,df,n):\n",
    "    if n> 0:\n",
    "        data_prep[f'{n}_days_before'] = data.loc[data.index - timedelta(days=n)]['KWH'].values\n",
    "    else:\n",
    "        data_prep[f'{-n}_days_after'] = data.loc[data.index + timedelta(days=-n)]['KWH'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "hours_shift_list = [-6,-5,-4,-3,-2,-1,1,3]\n",
    "days_shift_list = [1,3,7]\n",
    "for hours in hours_shift_list:\n",
    "    hour_shift(data_prep,data,hours)\n",
    "for days in days_shift_list:\n",
    "    days_shift(data_prep,data,days)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_more_features(df):\n",
    "    \"\"\"\n",
    "    Add 'month','day','hour' features\n",
    "    \"\"\"\n",
    "    data_prep = df.copy()\n",
    "    data_prep['month'] = df.index.month\n",
    "    data_prep['day'] = df.index.day\n",
    "    data_prep['hour'] = df.index.hour.astype(int)+1\n",
    "    return data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prep = add_more_features(data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prep = data_prep.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y_pred,y_label):\n",
    "    \"\"\"\n",
    "    Define Mean Absolute Percentage Error\n",
    "    \"\"\"\n",
    "    \n",
    "    mape = np.sum(abs(y_pred - y_label)) / np.sum(y_label)\n",
    "    return mape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGB\n",
    "xgb_features = ['KWH','1_hour_before','3_hour_before','1_days_before','3_days_before','7_days_before','month','day','hour']\n",
    "xgb_target = ['1_hour_after']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_prep[xgb_features],\n",
    "                                                data_prep[xgb_target],\n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 8896)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myxgb = XGBRegressor()\n",
    "\n",
    "depth_range = np.arange(7,10,1)\n",
    "num_estimators = np.arange(300,500,50)\n",
    "grid_params = {\n",
    "    'max_depth':depth_range,\n",
    "    'n_estimators':num_estimators\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(myxgb,\n",
    "                       grid_params,\n",
    "                       scoring = 'neg_mean_absolute_error',\n",
    "                      verbose = 1,\n",
    "                      n_jobs = -1,\n",
    "                       cv = 5,\n",
    "                      refit = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training..\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   46.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:03:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "train finished!\n"
     ]
    }
   ],
   "source": [
    "print('start training..')\n",
    "gsearch.fit(X_train,y_train)\n",
    "print('train finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_validation = model.predict(X_test)\n",
    "y_predict_train = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean_Percentage_Absolute_Error of the XGB model on validation set is 3.1%\n",
      "The Mean_Percentage_Absolute_Error of the XGB model on train set is 0.3%\n"
     ]
    }
   ],
   "source": [
    "xgb_score_validation = mape(y_predict_validation,y_test.values.reshape(1,-1))\n",
    "xgb_score_train = mape(y_predict_train,y_train.values.reshape(1,-1))\n",
    "print(f'The Mean_Percentage_Absolute_Error of the XGB model on validation set is {round(xgb_score_validation,3) * 100}%')\n",
    "print(f'The Mean_Percentage_Absolute_Error of the XGB model on train set is {round(xgb_score_train,3) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keras\n",
    "\n",
    "def buildTrain(train, past_hour, future_hour):\n",
    "    \"\"\"\n",
    "    Create the dataset with time-windows\n",
    "    \"\"\"\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0] - future_hour - past_hour):\n",
    "        X_train.append(np.array(train.iloc[i:i + past_hour]))\n",
    "        Y_train.append(np.array(train.iloc[i + past_hour:i + past_hour + future_hour][\"KWH\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(df):\n",
    "    \"\"\"\n",
    "    Scaling the dataset\n",
    "    \"\"\"\n",
    "    df = df.apply(lambda x :(x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Many-To-Many Predict\n",
    "# Predict 6 hours in the future using data from past 6 hours\n",
    "lstm_features = ['KWH''1_days_before','3_days_before','7_days_before','month','day','hour']\n",
    "\n",
    "print('Dataset Preparing...')\n",
    "data_lstm = data_prep[lstm_features]\n",
    "data_norm = normalization(data_lstm)\n",
    "X_train,y_train = buildTrain(data_norm,past_hour = 6,future_hour = 6)\n",
    "print('Dataset Preparing finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lstm,X_test_lstm,y_train_lstm,y_test_lstm = train_test_split(X_train,\n",
    "                                                y_train,\n",
    "                                                test_size = 0.1,\n",
    "                                                random_state = 8896)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildManyToManyModel(shape):\n",
    "    \"\"\"\n",
    "    Create LSTM-RNN\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape = (shape[1], shape[2]),return_sequences=True))\n",
    "    # output shape: (6, 1)\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform Target from 2 dimmension to 3 dimension\n",
    "y_train_lstm = y_train_lstm[:,:,np.newaxis]\n",
    "y_test_lstm = y_test_lstm[:,:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 6, 16)             1536      \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,553\n",
      "Trainable params: 1,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7133 samples, validate on 793 samples\n",
      "Epoch 1/500\n",
      "7133/7133 [==============================] - 3s 424us/step - loss: 0.1072 - val_loss: 0.0628\n",
      "Epoch 2/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0561 - val_loss: 0.0403\n",
      "Epoch 3/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0384 - val_loss: 0.0302\n",
      "Epoch 4/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0313 - val_loss: 0.0258\n",
      "Epoch 5/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0277 - val_loss: 0.0233\n",
      "Epoch 6/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0258 - val_loss: 0.0221\n",
      "Epoch 7/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0248 - val_loss: 0.0215\n",
      "Epoch 8/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0242 - val_loss: 0.0211\n",
      "Epoch 9/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0237 - val_loss: 0.0205\n",
      "Epoch 10/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0232 - val_loss: 0.0206\n",
      "Epoch 11/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 12/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0226 - val_loss: 0.0204\n",
      "Epoch 13/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0224 - val_loss: 0.0197\n",
      "Epoch 14/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0222 - val_loss: 0.0194\n",
      "Epoch 15/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0219 - val_loss: 0.0194\n",
      "Epoch 16/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0217 - val_loss: 0.0191\n",
      "Epoch 17/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0215 - val_loss: 0.0191\n",
      "Epoch 18/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0214 - val_loss: 0.0189\n",
      "Epoch 19/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0212 - val_loss: 0.0189\n",
      "Epoch 20/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0210 - val_loss: 0.0189\n",
      "Epoch 21/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0209 - val_loss: 0.0185\n",
      "Epoch 22/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0209 - val_loss: 0.0184\n",
      "Epoch 23/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0207 - val_loss: 0.0184\n",
      "Epoch 24/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0206 - val_loss: 0.0183\n",
      "Epoch 25/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0205 - val_loss: 0.0183\n",
      "Epoch 26/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0205 - val_loss: 0.0183\n",
      "Epoch 27/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0204 - val_loss: 0.0182\n",
      "Epoch 28/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0202 - val_loss: 0.0180\n",
      "Epoch 29/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0202 - val_loss: 0.0178\n",
      "Epoch 30/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0202 - val_loss: 0.0184\n",
      "Epoch 31/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0201 - val_loss: 0.0178\n",
      "Epoch 32/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0201 - val_loss: 0.0176\n",
      "Epoch 33/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0200 - val_loss: 0.0177\n",
      "Epoch 34/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0199 - val_loss: 0.0176\n",
      "Epoch 35/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0199 - val_loss: 0.0181\n",
      "Epoch 36/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0199 - val_loss: 0.0177\n",
      "Epoch 37/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0198 - val_loss: 0.0175\n",
      "Epoch 38/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0198 - val_loss: 0.0175\n",
      "Epoch 39/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0198 - val_loss: 0.0176\n",
      "Epoch 40/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0198 - val_loss: 0.0176\n",
      "Epoch 41/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0197 - val_loss: 0.0174\n",
      "Epoch 42/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 43/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 44/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 45/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0195 - val_loss: 0.0172\n",
      "Epoch 46/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0195 - val_loss: 0.0173\n",
      "Epoch 47/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0173\n",
      "Epoch 48/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0171\n",
      "Epoch 49/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0193 - val_loss: 0.0172\n",
      "Epoch 50/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0193 - val_loss: 0.0170\n",
      "Epoch 51/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 52/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0193 - val_loss: 0.0174\n",
      "Epoch 53/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 54/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0191 - val_loss: 0.0170\n",
      "Epoch 55/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0191 - val_loss: 0.0168\n",
      "Epoch 56/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0190 - val_loss: 0.0169\n",
      "Epoch 57/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0190 - val_loss: 0.0168\n",
      "Epoch 58/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 59/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0190 - val_loss: 0.0170\n",
      "Epoch 60/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0188 - val_loss: 0.0166\n",
      "Epoch 61/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 62/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0188 - val_loss: 0.0166\n",
      "Epoch 63/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0188 - val_loss: 0.0165\n",
      "Epoch 64/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0187 - val_loss: 0.0165\n",
      "Epoch 65/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 66/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0185 - val_loss: 0.0166\n",
      "Epoch 67/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 68/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0185 - val_loss: 0.0165\n",
      "Epoch 69/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0185 - val_loss: 0.0163\n",
      "Epoch 70/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0185 - val_loss: 0.0164\n",
      "Epoch 71/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0184 - val_loss: 0.0162\n",
      "Epoch 72/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0184 - val_loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0184 - val_loss: 0.0169\n",
      "Epoch 74/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0184 - val_loss: 0.0166\n",
      "Epoch 75/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0182 - val_loss: 0.0163\n",
      "Epoch 76/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0182 - val_loss: 0.0162\n",
      "Epoch 77/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0182 - val_loss: 0.0163\n",
      "Epoch 78/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0182 - val_loss: 0.0164\n",
      "Epoch 79/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0181 - val_loss: 0.0162\n",
      "Epoch 80/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0182 - val_loss: 0.0160\n",
      "Epoch 81/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0182 - val_loss: 0.0161\n",
      "Epoch 82/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0181 - val_loss: 0.0160\n",
      "Epoch 83/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0180 - val_loss: 0.0161\n",
      "Epoch 84/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0181 - val_loss: 0.0161\n",
      "Epoch 85/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0180 - val_loss: 0.0159\n",
      "Epoch 86/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 87/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 88/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0180 - val_loss: 0.0160\n",
      "Epoch 89/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0179 - val_loss: 0.0164\n",
      "Epoch 90/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0179 - val_loss: 0.0159\n",
      "Epoch 91/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0179 - val_loss: 0.0160\n",
      "Epoch 92/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0180 - val_loss: 0.0159\n",
      "Epoch 93/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0178 - val_loss: 0.0160\n",
      "Epoch 94/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0178 - val_loss: 0.0158\n",
      "Epoch 95/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0179 - val_loss: 0.0159\n",
      "Epoch 96/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0177 - val_loss: 0.0163\n",
      "Epoch 97/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0178 - val_loss: 0.0158\n",
      "Epoch 98/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0177 - val_loss: 0.0158\n",
      "Epoch 99/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0178 - val_loss: 0.0160\n",
      "Epoch 100/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0177 - val_loss: 0.0160\n",
      "Epoch 101/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0177 - val_loss: 0.0157\n",
      "Epoch 102/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0158\n",
      "Epoch 103/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0159\n",
      "Epoch 104/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0176 - val_loss: 0.0157\n",
      "Epoch 105/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0176 - val_loss: 0.0159\n",
      "Epoch 106/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0176 - val_loss: 0.0157\n",
      "Epoch 107/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0157\n",
      "Epoch 108/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0176 - val_loss: 0.0158\n",
      "Epoch 109/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0175 - val_loss: 0.0156\n",
      "Epoch 110/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 111/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0156\n",
      "Epoch 112/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 113/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0155\n",
      "Epoch 114/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0156\n",
      "Epoch 115/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0159\n",
      "Epoch 116/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0176 - val_loss: 0.0160\n",
      "Epoch 117/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0174 - val_loss: 0.0156\n",
      "Epoch 118/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 119/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 120/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0173 - val_loss: 0.0157\n",
      "Epoch 121/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0173 - val_loss: 0.0156\n",
      "Epoch 122/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 123/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0173 - val_loss: 0.0157\n",
      "Epoch 124/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0173 - val_loss: 0.0157\n",
      "Epoch 125/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0172 - val_loss: 0.0155\n",
      "Epoch 126/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0173 - val_loss: 0.0153\n",
      "Epoch 127/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 128/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0173 - val_loss: 0.0157\n",
      "Epoch 129/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0173 - val_loss: 0.0153\n",
      "Epoch 130/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 131/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0172 - val_loss: 0.0155\n",
      "Epoch 132/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0172 - val_loss: 0.0155\n",
      "Epoch 133/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 134/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0171 - val_loss: 0.0154\n",
      "Epoch 135/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0171 - val_loss: 0.0161\n",
      "Epoch 136/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0171 - val_loss: 0.0154\n",
      "Epoch 137/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 138/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0171 - val_loss: 0.0154\n",
      "Epoch 139/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0170 - val_loss: 0.0155\n",
      "Epoch 140/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0154\n",
      "Epoch 141/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0153\n",
      "Epoch 142/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0152\n",
      "Epoch 143/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0169 - val_loss: 0.0155\n",
      "Epoch 144/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0169 - val_loss: 0.0155\n",
      "Epoch 145/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 146/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0154\n",
      "Epoch 147/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0169 - val_loss: 0.0153\n",
      "Epoch 148/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0169 - val_loss: 0.0155\n",
      "Epoch 149/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0169 - val_loss: 0.0152\n",
      "Epoch 151/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0155\n",
      "Epoch 152/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0153\n",
      "Epoch 153/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 154/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 155/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 156/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0167 - val_loss: 0.0151\n",
      "Epoch 157/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0168 - val_loss: 0.0162\n",
      "Epoch 158/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 159/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 160/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0168 - val_loss: 0.0152\n",
      "Epoch 161/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0154\n",
      "Epoch 162/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0154\n",
      "Epoch 163/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0166 - val_loss: 0.0153\n",
      "Epoch 164/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0167 - val_loss: 0.0153\n",
      "Epoch 165/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0152\n",
      "Epoch 166/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 167/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 168/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 169/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 170/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 171/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0167 - val_loss: 0.0155\n",
      "Epoch 172/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 173/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0164 - val_loss: 0.0149\n",
      "Epoch 174/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 175/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 176/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 177/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 178/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 179/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 180/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 181/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0164 - val_loss: 0.0147\n",
      "Epoch 182/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 183/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 184/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 185/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 186/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 187/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 188/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 189/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 190/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 191/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 192/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 193/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 194/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0162 - val_loss: 0.0147\n",
      "Epoch 195/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0161 - val_loss: 0.0146\n",
      "Epoch 196/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 197/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 198/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0161 - val_loss: 0.0146\n",
      "Epoch 199/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0161 - val_loss: 0.0146\n",
      "Epoch 200/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 201/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 202/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 203/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 204/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 205/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 206/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 207/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 208/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0159 - val_loss: 0.0147\n",
      "Epoch 209/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 210/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0161 - val_loss: 0.0143\n",
      "Epoch 211/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 212/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0160 - val_loss: 0.0142\n",
      "Epoch 213/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 214/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 215/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 216/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 217/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 218/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0158 - val_loss: 0.0143\n",
      "Epoch 219/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0158 - val_loss: 0.0142\n",
      "Epoch 220/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 221/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 222/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 223/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 224/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 225/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 226/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0158 - val_loss: 0.0142\n",
      "Epoch 228/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 229/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 230/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 231/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 232/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 233/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 234/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 235/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0159 - val_loss: 0.0142\n",
      "Epoch 236/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 237/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 238/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 239/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 240/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 241/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 242/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 243/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 244/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 245/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0155 - val_loss: 0.0141\n",
      "Epoch 246/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 247/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 248/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 249/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 250/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0155 - val_loss: 0.0141\n",
      "Epoch 251/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 252/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 253/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0141\n",
      "Epoch 254/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 255/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 256/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 257/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 258/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0155 - val_loss: 0.0143\n",
      "Epoch 259/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 260/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 261/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 262/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 263/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 264/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 265/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 266/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 267/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 268/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 269/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 270/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 271/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 272/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 273/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 274/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 275/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 276/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 277/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 278/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 279/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 280/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 281/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 282/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 283/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0152 - val_loss: 0.0141\n",
      "Epoch 284/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 285/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 286/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 287/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 288/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0152 - val_loss: 0.0138\n",
      "Epoch 289/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0152 - val_loss: 0.0138\n",
      "Epoch 290/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 291/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 292/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 293/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 294/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 295/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 296/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 297/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 298/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 299/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 300/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 301/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 302/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 303/500\n",
      "7133/7133 [==============================] - 0s 35us/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 305/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 306/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 307/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 308/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 309/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 310/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 311/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 312/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 313/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 314/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 315/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 316/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 317/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 318/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 319/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 320/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 321/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 322/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 323/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 324/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 325/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 326/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 327/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 328/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 329/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 330/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 331/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0137\n",
      "Epoch 332/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 333/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 334/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 335/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 336/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0135\n",
      "Epoch 337/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 338/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 339/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 340/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 341/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0135\n",
      "Epoch 342/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 343/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 344/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 345/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 346/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 347/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 348/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0144\n",
      "Epoch 349/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 350/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0133\n",
      "Epoch 351/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 352/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0148 - val_loss: 0.0136\n",
      "Epoch 353/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0148 - val_loss: 0.0136\n",
      "Epoch 354/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0147 - val_loss: 0.0135\n",
      "Epoch 355/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 356/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 357/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 358/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 359/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 360/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 361/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0135\n",
      "Epoch 362/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 363/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 364/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 365/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 366/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 367/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 368/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 369/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 370/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 371/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 372/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 373/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 374/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 375/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 376/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 377/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 378/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0135\n",
      "Epoch 379/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 380/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0137\n",
      "Epoch 382/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 383/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0147 - val_loss: 0.0137\n",
      "Epoch 384/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 385/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 386/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 387/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 388/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 389/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 390/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0137\n",
      "Epoch 391/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 392/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 393/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 394/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 395/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0145 - val_loss: 0.0134\n",
      "Epoch 396/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 397/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 398/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 399/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 400/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 401/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 402/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 403/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 404/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 405/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 406/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 407/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 408/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 409/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 410/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 411/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 412/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 413/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 414/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 415/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 416/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 417/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 418/500\n",
      "7133/7133 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 419/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 420/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 421/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 422/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 423/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 424/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 425/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 426/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 427/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 428/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 429/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 430/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 431/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 432/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 433/500\n",
      "7133/7133 [==============================] - 0s 34us/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 434/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 435/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 436/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 437/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 438/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 439/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 440/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 441/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 442/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 443/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 444/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 445/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 446/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 447/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 448/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 449/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 450/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 451/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 452/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 453/500\n",
      "7133/7133 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 454/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 455/500\n",
      "7133/7133 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 456/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 457/500\n",
      "7133/7133 [==============================] - 0s 33us/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 00457: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2e14729e8>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = buildManyToManyModel(X_train_lstm.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train_lstm, y_train_lstm, epochs= 500, batch_size=128, validation_data=(X_test_lstm, y_test_lstm), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_test = model.predict(X_test_lstm)\n",
    "y_predict_train = model.predict(X_train_lstm)\n",
    "lstm_score_test = mape(y_predict_test,y_test_lstm)\n",
    "lstm_score_train = mape(y_predict_train,y_train_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean_Percentage_Absolute_Error of the LSTM model on validation set is 8.3%\n",
      "The Mean_Percentage_Absolute_Error of the LSTM model on train set is 8.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'The Mean_Percentage_Absolute_Error of the LSTM model on validation set is {round(lstm_score_test,3) * 100}%')\n",
    "print(f'The Mean_Percentage_Absolute_Error of the LSTM model on train set is {round(lstm_score_train,3) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
